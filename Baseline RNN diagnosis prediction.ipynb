{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZtKsbcbCEp-"},"outputs":[],"source":["import sys,os\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive, files\n","import pickle as pickle\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":755,"status":"ok","timestamp":1651910209590,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"sq22Y808CHTX","outputId":"72e2bf0c-f8f8-4dec-fd8d-f4276eb145dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651910209591,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"KREoVhHIV-TH","outputId":"cf76244b-df11-41c5-db16-408f4b0d88dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","if __name__=='__main__':\n","    print('Using device:', device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yZZHTckD6GR"},"outputs":[],"source":["DATA_PATH = '/content/drive/My Drive/BiteNetProject/data_processing/'\n","\n","data = pickle.load(open(os.path.join(DATA_PATH,'data.pkl'), 'rb'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kw6kNyPVbu5F"},"outputs":[],"source":["## FEATURES: list of patient visits, where each visit is a list of medical codes \n","seqs = [i[2] for i in data]\n","\n","##TARGET LABEL: diagnosis codes, one-hot vector of 170 \n","diag = [i[3] for i in data]\n","\n","\n","## number of unique medical codes\n","num_codes = max(set([code for visits in seqs for visit in visits for code in visit])) + 1\n","\n","\n","\n","\n","\n","assert len(seqs) == len(diag)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtplGsFob_Ic"},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, seqs, diag):\n","        self.x = seqs\n","        self.y = diag\n","    \n","    def __len__(self):\n","        \n","        return len(self.x)\n","    \n","    def __getitem__(self, index):\n","\n","        return self.x[index],self.y[index]\n","        \n","data = CustomDataset(seqs, diag)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651910210164,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"QFvEmuyYeFMP","outputId":"f15b6b91-abb3-439a-defb-3c199ec46dba"},"outputs":[{"output_type":"stream","name":"stdout","text":["<torch.utils.data.dataset.Subset object at 0x7f317468efd0>\n","Length of train dataset: 2998\n","Length of val dataset: 2998\n","Length of test dataset: 1500\n"]}],"source":["from torch.utils.data.dataset import random_split\n","\n","train_test_split = int(len(data)*0.8)\n","lengths = [train_test_split, len(data) - train_test_split]\n","train_data, test_data = random_split(data, lengths)\n","\n","\n","train_val_split = int(len(train_data)*0.5)\n","lengths = [train_val_split, len(train_data) - train_val_split]\n","train_data, val_data = random_split(train_data, lengths)\n","\n","print(train_data)\n","print(\"Length of train dataset:\", len(train_data))\n","print(\"Length of val dataset:\", len(val_data))\n","print(\"Length of test dataset:\", len(test_data))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAUx16Lthy9R"},"outputs":[],"source":["def collate_fn(data):\n","  sequences, labels = zip(*data)\n","\n","  num_patients = len(sequences)\n","  num_visits = len(sequences[0])\n","  num_codes = len(sequences[0][0])\n","\n","  x = torch.zeros((num_patients, num_visits, num_codes), dtype=torch.long)\n","  \n","  y = torch.tensor(labels, dtype=torch.float)\n","\n","  for i_patient, patient in enumerate(sequences):\n","        for j_visit, visit in enumerate(patient):            \n","            x[i_patient][j_visit] = torch.tensor(sequences[i_patient][j_visit],dtype=torch.long)\n","\n","\n","\n","\n","  return x, y\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQjznChpczkL"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def load_data(train_data, val_data, test_data, collate_fn):\n","    \n","    batch_size = 32\n","    ## iter will get a batch of size 32 [10 visits x 39 codes ] \n","\n","    train_loader = DataLoader(dataset = train_data, batch_size = 32, shuffle=True, collate_fn=collate_fn)\n","    val_loader = DataLoader(dataset = val_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","    test_loader = DataLoader(dataset = test_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","\n","    \n","    return train_loader, val_loader, test_loader\n","\n","\n","train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4Q8IP3T8_6q"},"outputs":[],"source":["def get_last_visit_state(x,hidden_states):\n","  ## for each patient in batch, get index of last visit\n","  ## input x 32,10,39  hidden states 32 10 128\n","  ## output 32 1\n","\n","  x = torch.sum(x,2)\n","\n","\n","  index = torch.zeros(x.shape,dtype=torch.int64)\n","  index[x!=0]=1\n","  index = torch.sum(index,1)\n","  index = torch.add(index,-1)\n","  last_visit_state = hidden_states[range(len(hidden_states)),index,:]\n","  \n","  return last_visit_state,index\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2qGXgD4r2Wo"},"outputs":[],"source":["def mask_sum(new_x,original_x):\n","  ## originalx 32 10 39 \n","  ## newx 32 10 39 128\n","  ## output 32 10 128\n","\n","  mask = torch.ones(new_x.shape,dtype=torch.int64)\n","\n","  for i in range(new_x.shape[0]):\n","    for j in range(new_x.shape[1]):\n","      if torch.sum(original_x[i,j,:]) == 0:\n","        mask[i,j] = torch.zeros(new_x.shape[2],new_x.shape[3])\n","\n","  new_x = torch.mul(new_x,mask)\n","\n","  new_x = torch.sum(new_x,2)\n","\n","  return new_x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1651910210334,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"BAVjfDbEeC4u","outputId":"57ac99d0-67c4-4637-80f5-0d31a85bb2ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"execute_result","data":{"text/plain":["NaiveRNN(\n","  (embedding_medcode): Embedding(3874, 128)\n","  (rnn_medcode): GRU(128, 128, batch_first=True, dropout=0.1)\n","  (fc): Linear(in_features=128, out_features=170, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":28}],"source":["class NaiveRNN(nn.Module):\n","    \n","    def __init__(self, num_codes, dropout = 0.1):\n","        super().__init__()\n","\n","        self.embedding_medcode = nn.Embedding(num_embeddings = num_codes, embedding_dim = 128)\n","        self.rnn_medcode = nn.GRU(128, hidden_size = 128, dropout = dropout, bidirectional = False, batch_first = True)\n","        self.fc = nn.Linear(128,170)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x): \n","        #print(x)\n","        original_x = x         ##print(\"start x\",x.shape) ## 32,10,39 ##Each of the 39s is a medical code\n","        batch_size = x.shape[0]\n","\n","        x = self.embedding_medcode(x) ##print(\"post embedding\",x.shape) ## 32, 10, 39, 128\n","\n","        x = mask_sum(x,original_x) ##print(\"after sum\",x.shape) ## 32 10 128\n"," \n","        rnn_medcode_output, last_h_n = self.rnn_medcode(x) #print(\"after rnn output\",rnn_medcode_output.shape )  ## 32 10 128   \n","        \n","        rnn_medcode_last_hs,index = get_last_visit_state(original_x,rnn_medcode_output) ##True last hidden state 32 128\n","\n","        logits = self.fc(rnn_medcode_last_hs)     #print(\"after linear layer shape\",logits)    ## 32 170 \n","        #print(\"logits\",logits.shape)\n","        probs = self.sigmoid(logits)  ##after sigmoid 32 170 \n","        #print(\"probs\",probs.shape)\n","        \n","\n","        return probs\n","\n","\n","model = NaiveRNN(num_codes = num_codes)\n","model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbyU7oUcpm7E"},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L35GTsBzp4gI"},"outputs":[],"source":["from sklearn.utils.validation import indexable\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_recall_curve, auc\n","from sklearn.metrics import precision_score\n","\n","def eval_model(model, loader):\n","    model.eval()\n","    y_pred = torch.LongTensor()\n","    y_true = torch.LongTensor()\n","    model.eval()\n","    for x, y in loader:\n","        y_hat = model(x)\n","        y_hat = y_hat > 0.5\n","        y_hat = y_hat.int()\n","        y = y.int()\n","        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n","        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n","    \n","    precision = precision_score(y_true,y_pred,average=\"micro\")\n","\n","\n","    return precision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjO7i1LHrQiH"},"outputs":[],"source":["def train(model, train_loader, val_loader, n_epochs, print_train_results=True):\n","    for epoch in range(n_epochs):\n","      model.train()\n","      train_loss = 0\n","      for x, y in train_loader:\n","        loss = None\n","        optimizer.zero_grad()\n","        y_hat = model(x)\n","\n","        loss = criterion(y_hat,y)\n","        loss.backward()\n","        optimizer.step()\n","        # your code here\n","        \n","        train_loss += loss.item()\n","      train_loss = train_loss / len(train_loader)\n","      if print_train_results==True:\n","        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n","      precision = eval_model(model, val_loader)\n","      if print_train_results==True:\n","        print('Epoch: {} \\t Validation overall precision p:{:.3f}'.format(epoch+1,precision))\n","      "]},{"cell_type":"code","source":["n_epochs = 10\n","train(model, train_loader, val_loader, n_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHHLSpPMgkp9","executionInfo":{"status":"ok","timestamp":1651910264183,"user_tz":240,"elapsed":53853,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}},"outputId":"8a1d1ee4-551a-43ce-d1fb-0651138a1d5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 \t Training Loss: 0.242396\n","Epoch: 1 \t Validation overall precision p:0.582\n","Epoch: 2 \t Training Loss: 0.159333\n","Epoch: 2 \t Validation overall precision p:0.583\n","Epoch: 3 \t Training Loss: 0.156842\n","Epoch: 3 \t Validation overall precision p:0.601\n","Epoch: 4 \t Training Loss: 0.155679\n","Epoch: 4 \t Validation overall precision p:0.644\n","Epoch: 5 \t Training Loss: 0.154224\n","Epoch: 5 \t Validation overall precision p:0.640\n","Epoch: 6 \t Training Loss: 0.153298\n","Epoch: 6 \t Validation overall precision p:0.689\n","Epoch: 7 \t Training Loss: 0.152681\n","Epoch: 7 \t Validation overall precision p:0.626\n","Epoch: 8 \t Training Loss: 0.152045\n","Epoch: 8 \t Validation overall precision p:0.651\n","Epoch: 9 \t Training Loss: 0.151286\n","Epoch: 9 \t Validation overall precision p:0.649\n","Epoch: 10 \t Training Loss: 0.150777\n","Epoch: 10 \t Validation overall precision p:0.652\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, test_number):\n","      precision = eval_model(model, test_loader)\n","      \n","      \n","      print('Test: test_number{} \\t Test precision :{:.3f}'\n","              .format(test_number+1,precision))"],"metadata":{"id":"UZz7I-E8gksr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xwtest_number = 3\n","for i in range(test_number):\n","  train_test_split = int(len(data)*0.8)\n","  lengths = [train_test_split, len(data) - train_test_split]\n","  train_data, test_data = random_split(data, lengths)\n","\n","\n","  train_val_split = int(len(train_data)*0.5)\n","  lengths = [train_val_split, len(train_data) - train_val_split]\n","  train_data, val_data = random_split(train_data, lengths)\n","  \n","  train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","  \n","  newmodel = NaiveRNN(num_codes = num_codes)\n","  criterion = nn.BCELoss()\n","  optimizer = optim.Adam(newmodel.parameters(), lr=0.001)\n","\n","  n_epochs = 10\n","  train(newmodel, train_loader, val_loader, n_epochs,print_train_results=False)\n","  test(newmodel, test_loader, i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_OpRKrWg8zk","executionInfo":{"status":"ok","timestamp":1651910446959,"user_tz":240,"elapsed":169594,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}},"outputId":"f0d0ac7e-5d58-40f2-c096-5b3b4a9d91d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["Test: test_number1 \t Test precision :0.632\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["Test: test_number2 \t Test precision :0.626\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["Test: test_number3 \t Test precision :0.628\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Baseline RNN diagnosis prediction.ipynb","provenance":[{"file_id":"1Da-G_N2XDUNlSKoARvAlaUOhAkEtzubB","timestamp":1651355435602}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}