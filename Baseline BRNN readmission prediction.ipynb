{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3104,"status":"ok","timestamp":1651965576878,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"6ZtKsbcbCEp-"},"outputs":[],"source":["import sys,os\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive, files\n","import pickle as pickle\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"elapsed":2455,"status":"error","timestamp":1651965579326,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"sq22Y808CHTX","outputId":"3c79ccd6-aafc-471a-f5cd-944991849ccc"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-445c1eb4742f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":171,"status":"aborted","timestamp":1651965579312,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"KREoVhHIV-TH"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","if __name__=='__main__':\n","    print('Using device:', device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":174,"status":"aborted","timestamp":1651965579316,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"4yZZHTckD6GR"},"outputs":[],"source":["DATA_PATH = '/content/drive/My Drive/BiteNetProject/data_processing/'\n","\n","data = pickle.load(open(os.path.join(DATA_PATH,'data.pkl'), 'rb'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":175,"status":"aborted","timestamp":1651965579317,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"kw6kNyPVbu5F"},"outputs":[],"source":["## list of patient visits, where each visit is a list of medical codes \n","seqs= [i[2] for i in data]\n","\n","\n","## target label of readmission \n","readmission = [i[4] for i in data]\n","\n","\n","## number of unique medical codes\n","num_codes = max(set([code for visits in seqs for visit in visits for code in visit])) + 1\n","\n","\n","print(num_codes)\n","\n","\n","\n","assert len(seqs) == len(readmission)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtplGsFob_Ic","executionInfo":{"status":"aborted","timestamp":1651965579318,"user_tz":240,"elapsed":175,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, seqs, readmission):\n","        self.x = seqs\n","        self.y = readmission\n","    \n","    def __len__(self):\n","        \n","        return len(self.x)\n","    \n","    def __getitem__(self, index):\n","\n","        return self.x[index],self.y[index]\n","        \n","data = CustomDataset(seqs, readmission)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":176,"status":"aborted","timestamp":1651965579319,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"QFvEmuyYeFMP"},"outputs":[],"source":["from torch.utils.data.dataset import random_split\n","\n","train_test_split = int(len(data)*0.8)\n","lengths = [train_test_split, len(data) - train_test_split]\n","train_data, test_data = random_split(data, lengths)\n","\n","\n","train_val_split = int(len(train_data)*0.5)\n","lengths = [train_val_split, len(train_data) - train_val_split]\n","train_data, val_data = random_split(train_data, lengths)\n","\n","print(train_data)\n","print(\"Length of train dataset:\", len(train_data))\n","print(\"Length of val dataset:\", len(val_data))\n","print(\"Length of test dataset:\", len(test_data))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAUx16Lthy9R","executionInfo":{"status":"aborted","timestamp":1651965579319,"user_tz":240,"elapsed":175,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def collate_fn(data):\n","    \"\"\"\n","    TODO: Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n","        sequences to the sample shape (max # visits, max # diagnosis codes). The padding infomation\n","        is stored in `mask`.\n","    \n","    Arguments:\n","        data: a list of samples fetched from `CustomDataset`\n","        \n","    Outputs:\n","        x: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.long\n","        masks: a tensor of shape (# patiens, max # visits, max # diagnosis codes) of type torch.bool\n","        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n","        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n","        y: a tensor of shape (# patiens) of type torch.float\n","        \n","    Note that you can obtains the list of diagnosis codes and the list of hf labels\n","        using: `sequences, labels = zip(*data)`\n","    \"\"\"\n","\n","    sequences, labels = zip(*data)\n","   \n","\n","    y = torch.tensor(labels, dtype=torch.float)\n","    \n","    num_patients = len(sequences)\n","    num_visits = [len(patient) for patient in sequences]\n","    num_codes = [len(visit) for patient in sequences for visit in patient]\n","\n","    max_num_visits = max(num_visits)\n","    max_num_codes = max(num_codes)\n","    \n","    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n","\n","    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n","    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n","    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n","\n","    \n","            \n","    for i_patient, patient in enumerate(sequences):\n","        for j_visit, visit in enumerate(patient):\n","            \"\"\"\n","            TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n","            \"\"\"\n","            codes_needed = max_num_codes - len(sequences[i_patient][j_visit])\n","            \n","            codes_padding = torch.tensor(([0] * codes_needed),dtype=torch.long)\n","            \n","            original_visits = torch.tensor(sequences[i_patient][j_visit],dtype=torch.long)\n","        \n","            x[i_patient][j_visit] = torch.cat([original_visits,codes_padding],0)\n","            \n","\n","    \n","    ##Construct Masks\n","    \n","    for i_patient, patient in enumerate(sequences):\n","        for j_visit, visit in enumerate(patient):\n","            #print(sequences[i_patient])\n","            \n","            curr_codes = len(sequences[i_patient][j_visit])\n","            \n","            num_codes_needed = max_num_codes - curr_codes\n","            \n","            #print(sequences[i_patient][j_visit])\n","            #print(\"max_codes\",max_num_codes,\"curr_codes\",curr_codes,\"num_codes_needed\",num_codes_needed,)\n","            \n","            mask_real_portion = sequences[i_patient][j_visit]\n","            mask_padded_portion = [0] * num_codes_needed\n","            \n","            masks_total = mask_real_portion + mask_padded_portion\n","            \n","            masks[i_patient][j_visit] = torch.Tensor(masks_total)\n","            \n","            \n","\n","    \n","    fake_visits_map = {}\n","    \n","    for i_patient in range(len(masks)):\n","        for j_visit in range(len(masks[i_patient])):\n","            if torch.sum(masks[i_patient][j_visit]) == torch.tensor(0):\n","                \n","                fake_visits_map[i_patient] = j_visit\n","                break\n","\n","    \n","    rev_x = torch.clone(x)  \n","    \n","    for i_patient in range(len(x)):\n","        for j_visit in range(len(x[i_patient])):\n","            if i_patient in fake_visits_map:\n","                first_fake = fake_visits_map[i_patient]\n","                rev_x[i_patient][:first_fake] = torch.flip(rev_x[i_patient][:first_fake],[0])\n","            else:\n","                rev_x[i_patient] = torch.flip(rev_x[i_patient],[0])\n","    \n","\n","    \n","    rev_masks = torch.clone(masks)\n","\n","    \n","    for i_patient in range(len(masks)):\n","        for j_visit in range(len(masks[i_patient])):\n","            if i_patient in fake_visits_map:\n","                first_fake = fake_visits_map[i_patient]\n","                rev_masks[i_patient][:first_fake]= torch.flip(rev_masks[i_patient][:first_fake],[0])\n","            else:\n","                rev_masks[i_patient] = torch.flip(rev_masks[i_patient],[0])   \n","    \n","        \n","    #print(\"x.dtype\",x.dtype,\"rev_x.dtype\",rev_x.dtype)\n","    return x, rev_x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQjznChpczkL","executionInfo":{"status":"aborted","timestamp":1651965579320,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def load_data(train_data, val_data, test_data, collate_fn):\n","    \n","    batch_size = 32\n","    ## iter will get a batch of size 32 [10 visits x 39 codes ] \n","\n","    train_loader = DataLoader(dataset = train_data, batch_size = 32, shuffle=True, collate_fn=collate_fn)\n","    val_loader = DataLoader(dataset = val_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","    test_loader = DataLoader(dataset = test_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","\n","    \n","    return train_loader, val_loader, test_loader\n","\n","\n","train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4Q8IP3T8_6q","executionInfo":{"status":"aborted","timestamp":1651965579320,"user_tz":240,"elapsed":177,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def get_last_visit_state(x,hidden_states):\n","  ## for each patient in batch, get index of last visit\n","  ## input x 32,10,39  hidden states 32 10 128\n","  ## output 32 1\n","\n","  x = torch.sum(x,2)\n","\n","\n","  index = torch.zeros(x.shape,dtype=torch.int64)\n","  index[x!=0]=1\n","  index = torch.sum(index,1)\n","  index = torch.add(index,-1)\n","\n","  last_visit_state = hidden_states[range(len(hidden_states)),index,:]\n","  \n","  return last_visit_state\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2qGXgD4r2Wo","executionInfo":{"status":"aborted","timestamp":1651965579321,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def mask_sum(new_x,original_x):\n","  ## originalx 32 10 39 \n","  ## newx 32 10 39 128\n","  ## output 32 10 128\n","\n","  mask = torch.ones(new_x.shape,dtype=torch.int64)\n","\n","  for i in range(new_x.shape[0]):\n","    for j in range(new_x.shape[1]):\n","      if torch.sum(original_x[i,j,:]) == 0:\n","        mask[i,j] = torch.zeros(new_x.shape[2],new_x.shape[3])\n","\n","  new_x = torch.mul(new_x,mask)\n","\n","  new_x = torch.sum(new_x,2)\n","\n","  return new_x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":176,"status":"aborted","timestamp":1651965579321,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"BAVjfDbEeC4u"},"outputs":[],"source":["class BRNN(nn.Module):\n","    \n","    def __init__(self, num_codes, dropout = 0.5):\n","        super().__init__()\n","\n","        self.embedding_medcode = nn.Embedding(num_embeddings = num_codes, embedding_dim = 128)\n","        self.rnn_medcode = nn.GRU(128, hidden_size = 128, dropout = dropout, bidirectional = False, batch_first = True)\n","        self.rev_rnn_medcode = nn.GRU(128, hidden_size = 128, dropout = dropout, bidirectional = False, batch_first = True)\n","        self.fc = nn.Linear(256,1)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x, rev_x): \n","\n","        batch_size = x.shape[0]\n","        \n","        original_x = x         ##print(\"start x\",x.shape) ## 32,10,39 ##Each of the 39s is a medical code\n","        x = self.embedding_medcode(x) ##print(\"post embedding\",x.shape) ## 32, 10, 39, 128\n","        x = mask_sum(x,original_x) ##print(\"after sum\",x.shape) ## 32 10 128\n","        rnn_medcode_output, last_h_n = self.rnn_medcode(x) #print(\"after rnn output\",rnn_medcode_output.shape )  ## 32 10 128   \n","        rnn_medcode_last_hs = get_last_visit_state(original_x,rnn_medcode_output) ##True last hidden state 32 128\n","        #print(rnn_medcode_last_hs.shape)\n","\n","        original_rev_x = rev_x\n","        rev_x = self.embedding_medcode(rev_x)\n","        rev_x = mask_sum(rev_x,original_rev_x)\n","        rev_rnn_medcode_output, rev_last_h_n = self.rev_rnn_medcode(rev_x) #print(\"after rnn output\",rnn_medcode_output.shape )  ## 32 10 128  \n","        rev_rnn_medcode_last_hs = rev_rnn_medcode_output[:,0,:]\n","        \n","\n","        \n","        logits = self.fc(torch.cat([rnn_medcode_last_hs,rev_rnn_medcode_last_hs],1))     #print(\"after linear layer shape\",logits)    ## 32 1 \n","        \n","        probs = self.sigmoid(logits)\n","\n","        result = probs.view(batch_size) ## 32\n","\n","\n","        return result\n","\n","\n","model = BRNN(num_codes = num_codes)\n","model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbyU7oUcpm7E","executionInfo":{"status":"aborted","timestamp":1651965579322,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L35GTsBzp4gI","executionInfo":{"status":"aborted","timestamp":1651965579322,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from sklearn.utils.validation import indexable\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_recall_curve, auc\n","\n","def eval_model(model, loader):\n","    model.eval()\n","    y_pred = torch.LongTensor()\n","    y_score = torch.Tensor()\n","    y_true = torch.LongTensor()\n","    model.eval()\n","    for x, rev_x, y in loader:\n","        y_hat = model(x,rev_x) \n","        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n","        y_hat = (y_hat > 0.5).int()\n","\n","        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n","        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n","\n","    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n","    pr_auc = auc(recall, precision)\n","    \n","\n","\n","    return pr_auc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjO7i1LHrQiH","executionInfo":{"status":"aborted","timestamp":1651965579323,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def train(model, train_loader, val_loader, n_epochs, print_train_results=True):\n","    for epoch in range(n_epochs):\n","      model.train()\n","      train_loss = 0\n","      for x, rev_x, y in train_loader:\n","        loss = None\n","        optimizer.zero_grad()\n","        y_hat = model(x,rev_x)\n","        \n","        \n","        loss = criterion(y_hat,y)\n","        loss.backward()\n","        optimizer.step()\n","        # your code here\n","        \n","        train_loss += loss.item()\n","      train_loss = train_loss / len(train_loader)\n","      if print_train_results==True:\n","        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n","      pr_auc = eval_model(model, val_loader)\n","      if print_train_results==True:\n","        print('Epoch: {} \\t Validation pr_auc:{:.3f}'\n","              .format(epoch+1,pr_auc))\n","      \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TALVyIpxr4D0","executionInfo":{"status":"aborted","timestamp":1651965579323,"user_tz":240,"elapsed":175,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5Ldkp6lr4HS","executionInfo":{"status":"aborted","timestamp":1651965579324,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["n_epochs = 20\n","train(model, train_loader, val_loader, n_epochs)"]},{"cell_type":"code","source":[""],"metadata":{"id":"bAbndw27fs7z","executionInfo":{"status":"aborted","timestamp":1651965579324,"user_tz":240,"elapsed":175,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, data, test_number):\n","      pr_auc = eval_model(model, test_loader)\n","      print('Test number: {} \\t test pr_auc:{:.3f}'\n","            .format(test_number+1,pr_auc))\n","      \n"],"metadata":{"id":"BjmBOXNTu-2I","executionInfo":{"status":"aborted","timestamp":1651965579325,"user_tz":240,"elapsed":176,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_number = 3\n","for i in range(test_number):\n","  train_test_split = int(len(data)*0.8)\n","  lengths = [train_test_split, len(data) - train_test_split]\n","  train_data, test_data = random_split(data, lengths)\n","\n","\n","  train_val_split = int(len(train_data)*0.5)\n","  lengths = [train_val_split, len(train_data) - train_val_split]\n","  train_data, val_data = random_split(train_data, lengths)\n","\n","  train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","\n","  newmodel = BRNN(num_codes = num_codes)\n","  criterion = nn.BCELoss()\n","  optimizer = optim.Adam(newmodel.parameters(), lr=0.001)\n","\n","  n_epochs = \n","  train(newmodel, train_loader, val_loader, n_epochs,print_train_results=False)\n","  test(newmodel, test_loader, i)"],"metadata":{"id":"1YOpW8Xpu_Xd","executionInfo":{"status":"aborted","timestamp":1651965579635,"user_tz":240,"elapsed":485,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Baseline BRNN readmission prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}