{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3525,"status":"ok","timestamp":1651957163807,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"6ZtKsbcbCEp-"},"outputs":[],"source":["import sys,os\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive, files\n","import pickle as pickle\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32703,"status":"ok","timestamp":1651957196498,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"sq22Y808CHTX","outputId":"c2975262-e9d8-4425-c70a-76103de86e76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1651957196500,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"KREoVhHIV-TH","outputId":"bd69fe0f-39cd-4fc7-8ec3-70445a69a743"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","if __name__=='__main__':\n","    print('Using device:', device)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2968,"status":"ok","timestamp":1651957199457,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"4yZZHTckD6GR"},"outputs":[],"source":["DATA_PATH = '/content/drive/My Drive/BiteNetProject/data_processing/'\n","\n","data = pickle.load(open(os.path.join(DATA_PATH,'data.pkl'), 'rb'))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1651957199458,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"kw6kNyPVbu5F"},"outputs":[],"source":["## list of patient visits, where each visit is a list of medical codes \n","seqs= [i[2] for i in data]\n","\n","## remove 0s from visits and patients - we will pad with mask later\n","\n","for patient_i, patient in enumerate(seqs):\n","  seqs[patient_i] = [visit for visit in patient if sum(visit)>0]\n","\n","for patient_i, patient in enumerate(seqs):\n","  for visit_j, visit in enumerate(patient):\n","    patient[visit_j] = [medcode for medcode in visit if medcode > 0]\n","\n","\n","## target label of readmission \n","readmission = [i[4] for i in data]\n","\n","\n","## number of unique medical codes\n","num_codes = max(set([code for visits in seqs for visit in visits for code in visit])) + 1\n","\n","\n","assert len(seqs) == len(readmission)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dtplGsFob_Ic","executionInfo":{"status":"ok","timestamp":1651957199459,"user_tz":240,"elapsed":17,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, seqs, readmission):\n","        self.x = seqs\n","        self.y = readmission\n","    \n","    def __len__(self):\n","        \n","        return len(self.x)\n","    \n","    def __getitem__(self, index):\n","\n","        return self.x[index],self.y[index]\n","        \n","data = CustomDataset(seqs, readmission)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1651957199460,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"QFvEmuyYeFMP","outputId":"4a6e658b-ce23-4009-d0b7-8f4cdea37233"},"outputs":[{"output_type":"stream","name":"stdout","text":["<torch.utils.data.dataset.Subset object at 0x7fd1126e6910>\n","Length of train dataset: 2998\n","Length of val dataset: 2998\n","Length of test dataset: 1500\n"]}],"source":["from torch.utils.data.dataset import random_split\n","\n","train_test_split = int(len(data)*0.8)\n","lengths = [train_test_split, len(data) - train_test_split]\n","train_data, test_data = random_split(data, lengths)\n","\n","\n","train_val_split = int(len(train_data)*0.5)\n","lengths = [train_val_split, len(train_data) - train_val_split]\n","train_data, val_data = random_split(train_data, lengths)\n","\n","print(train_data)\n","print(\"Length of train dataset:\", len(train_data))\n","print(\"Length of val dataset:\", len(val_data))\n","print(\"Length of test dataset:\", len(test_data))\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aAUx16Lthy9R","executionInfo":{"status":"ok","timestamp":1651957199460,"user_tz":240,"elapsed":14,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def collate_fn(data):\n","    sequences, labels = zip(*data)\n","   \n","    y = torch.tensor(labels, dtype=torch.float)\n","    \n","    num_patients = len(sequences)\n","    num_visits = [len(patient) for patient in sequences]\n","    num_codes = [len(visit) for patient in sequences for visit in patient]\n","\n","    max_num_visits = 10\n","    max_num_codes = 39\n","    \n","    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n","    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n","    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n","    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n","\n","    #Pad visits \n","    for i_patient, patient in enumerate(sequences):\n","        for j_visit, visit in enumerate(patient):\n","            codes_needed = max_num_codes - len(sequences[i_patient][j_visit])\n","            codes_padding = torch.tensor(([0] * codes_needed),dtype=torch.long)\n","            original_visits = torch.tensor(sequences[i_patient][j_visit],dtype=torch.long)\n","            x[i_patient][j_visit] = torch.cat([original_visits,codes_padding],0)\n","            \n","    #Pad codes within visits\n","    for i_patient, patient in enumerate(sequences):\n","        for j_visit, visit in enumerate(patient):\n","            curr_codes = len(sequences[i_patient][j_visit])\n","            num_codes_needed = max_num_codes - curr_codes\n","            mask_real_portion = sequences[i_patient][j_visit]\n","            mask_padded_portion = [0] * num_codes_needed\n","            masks_total = mask_real_portion + mask_padded_portion\n","            masks[i_patient][j_visit] = torch.Tensor(masks_total)\n","    \n","    #Create mask     \n","    fake_visits_map = {}\n","    \n","    for i_patient in range(len(masks)):\n","        for j_visit in range(len(masks[i_patient])):\n","            if torch.sum(masks[i_patient][j_visit]) == torch.tensor(0):\n","                fake_visits_map[i_patient] = j_visit\n","                break\n","\n","    #Create rev_x\n","    rev_x = torch.clone(x)  \n","    \n","    for i_patient in range(len(x)):\n","        for j_visit in range(len(x[i_patient])):\n","            if i_patient in fake_visits_map:\n","                first_fake = fake_visits_map[i_patient]\n","                rev_x[i_patient][:first_fake] = torch.flip(rev_x[i_patient][:first_fake],[0])\n","            else:\n","                rev_x[i_patient] = torch.flip(rev_x[i_patient],[0])\n","    \n","    #Create rev_mask for rev_x\n","    rev_masks = torch.clone(masks)\n","\n","    for i_patient in range(len(masks)):\n","        for j_visit in range(len(masks[i_patient])):\n","            if i_patient in fake_visits_map:\n","                first_fake = fake_visits_map[i_patient]\n","                rev_masks[i_patient][:first_fake]= torch.flip(rev_masks[i_patient][:first_fake],[0])\n","            else:\n","                rev_masks[i_patient] = torch.flip(rev_masks[i_patient],[0])   \n","    \n","        \n","    #print(\"x.dtype\",x.dtype,\"rev_x.dtype\",rev_x.dtype)\n","    return x, masks, rev_x, rev_masks, y"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kQjznChpczkL","executionInfo":{"status":"ok","timestamp":1651957199461,"user_tz":240,"elapsed":13,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def load_data(train_data, val_data, test_data, collate_fn):\n","    \n","    batch_size = 32\n","    ## iter will get a batch of size 32 [10 visits x 39 codes ] \n","\n","    train_loader = DataLoader(dataset = train_data, batch_size = 32, shuffle=True, collate_fn=collate_fn)\n","    val_loader = DataLoader(dataset = val_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","    test_loader = DataLoader(dataset = test_data, batch_size = 32, shuffle=False, collate_fn=collate_fn)\n","\n","    \n","    return train_loader, val_loader, test_loader\n","\n","\n","train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["def sum_embeddings_with_mask(x, masks):\n","\n","    x = x * masks.unsqueeze(-1)\n","    x = torch.sum(x, dim = -2)\n","    return x"],"metadata":{"id":"W6JDDv6QHkKH","executionInfo":{"status":"ok","timestamp":1651957199462,"user_tz":240,"elapsed":12,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class AlphaAttention(torch.nn.Module):\n","\n","    def __init__(self, hidden_dim):\n","        super().__init__()\n","        self.a_att = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, g):\n","        linear_a_att = self.a_att(g)\n","        return torch.softmax(linear_a_att, dim = 1)"],"metadata":{"id":"-dg8ArmsDGIX","executionInfo":{"status":"ok","timestamp":1651957199893,"user_tz":240,"elapsed":15,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class BetaAttention(torch.nn.Module):\n","\n","    def __init__(self, hidden_dim):\n","        super().__init__()\n","        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, h):\n","        linear_b_att = self.b_att(h)\n","        return torch.tanh(linear_b_att)\n","    "],"metadata":{"id":"RhivXCAqDK0l","executionInfo":{"status":"ok","timestamp":1651957199896,"user_tz":240,"elapsed":16,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def attention_sum(alpha, beta, rev_v, rev_masks):\n","\n","    rev_v_embed_dim = rev_v.shape[-1]\n","    beta_hidden_dim = beta.shape[-1]\n","    \n","    rev_masks = torch.sum(rev_masks,dim=2)\n","    rev_masks = rev_masks.unsqueeze(2)\n","\n","    rev_masks = rev_masks.expand(-1,-1,rev_v_embed_dim)\n","\n","    rev_masks = rev_masks.apply_(lambda x: min(x,1))\n","    \n","    true_visits = torch.mul(rev_masks,rev_v)\n","\n","\n","    alpha = alpha.expand(-1,-1,beta_hidden_dim)\n","    attention = torch.mul(beta,alpha)\n","\n","    \n","    attention = torch.mul(attention,true_visits) \n","    \n","    attention_sum = torch.sum(attention,1)\n","    \n","\n","\n","    return attention_sum\n","\n","    "],"metadata":{"id":"qJ0Ye9TkDJ9K","executionInfo":{"status":"ok","timestamp":1651957199898,"user_tz":240,"elapsed":17,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1651957199899,"user":{"displayName":"Jacky S","userId":"12056070040940406337"},"user_tz":240},"id":"BAVjfDbEeC4u","outputId":"82239eaa-f070-4978-f7f9-53839bef7bbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RETAIN(\n","  (embedding): Embedding(3874, 128)\n","  (rnn_a): GRU(128, 128, batch_first=True)\n","  (rnn_b): GRU(128, 128, batch_first=True)\n","  (att_a): AlphaAttention(\n","    (a_att): Linear(in_features=128, out_features=1, bias=True)\n","  )\n","  (att_b): BetaAttention(\n","    (b_att): Linear(in_features=128, out_features=128, bias=True)\n","  )\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":14}],"source":["class RETAIN(nn.Module):\n","    \n","    def __init__(self, num_codes, embedding_dim=128):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(num_codes, embedding_dim)\n","   \n","        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n","\n","        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n","\n","        self.att_a = AlphaAttention(embedding_dim)\n","\n","        self.att_b = BetaAttention(embedding_dim)\n","\n","        self.fc = nn.Linear(embedding_dim, 1)\n","\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, x, masks, rev_x, rev_masks):\n","\n","\n","  \n","        rev_x = self.embedding(rev_x)\n","\n","        rev_x = sum_embeddings_with_mask(rev_x, rev_masks)\n","\n","        g, _ = self.rnn_a(rev_x)\n","        h, _ = self.rnn_b(rev_x)\n","\n","        alpha = self.att_a(g)\n","        beta = self.att_b(h)\n","\n","        c = attention_sum(alpha, beta, rev_x, rev_masks)\n","\n","        logits = self.fc(c)\n","        probs = self.sigmoid(logits)\n","        return probs.squeeze()\n","    \n","\n","# load the model here\n","retainmodel = RETAIN(num_codes = num_codes)\n","retainmodel"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"gbyU7oUcpm7E","executionInfo":{"status":"ok","timestamp":1651957199900,"user_tz":240,"elapsed":15,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(retainmodel.parameters(), lr=0.001)\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"L35GTsBzp4gI","executionInfo":{"status":"ok","timestamp":1651957200268,"user_tz":240,"elapsed":382,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["from sklearn.utils.validation import indexable\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_recall_curve, auc\n","\n","\n","def eval_model(model, val_loader):\n","    \n","    model.eval()\n","    y_pred = torch.LongTensor()\n","    y_score = torch.Tensor()\n","    y_true = torch.LongTensor()\n","    model.eval()\n","    for x, masks, rev_x, rev_masks, y in val_loader:\n","        y_hat = model(x, masks, rev_x, rev_masks) \n","        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n","        y_hat = (y_hat > 0.5).int()\n","\n","        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n","        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n","\n","    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n","    \n","    pr_auc = auc(recall, precision)\n","\n","    return pr_auc"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"zjO7i1LHrQiH","executionInfo":{"status":"ok","timestamp":1651957200270,"user_tz":240,"elapsed":11,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"outputs":[],"source":["def train(model, train_loader, val_loader, n_epochs, display_results = True):\n","    for epoch in range(n_epochs):\n","      model.train()\n","      train_loss = 0\n","      for x, masks, rev_x, rev_masks, y in train_loader:\n","        loss = None\n","        optimizer.zero_grad()\n","        y_hat = model(x, masks, rev_x, rev_masks)\n","        \n","        \n","        loss = criterion(y_hat,y)\n","        loss.backward()\n","        optimizer.step()\n","        # your code here\n","        \n","        train_loss += loss.item()\n","      train_loss = train_loss / len(train_loader)\n","      if display_results is True:\n","        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n","      pr_auc = eval_model(model, val_loader)\n","      if display_results is True:\n","        print('Epoch: {} \\t Validation pr_auc:{:.3f}'\n","              .format(epoch+1,pr_auc))\n","        \n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5Ldkp6lr4HS","executionInfo":{"status":"ok","timestamp":1651957263177,"user_tz":240,"elapsed":62916,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}},"outputId":"3e121f16-ff53-4b39-9cf8-7ad84c539716"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 \t Training Loss: 0.574030\n","Epoch: 1 \t Validation pr_auc:0.305\n","Epoch: 2 \t Training Loss: 0.339782\n","Epoch: 2 \t Validation pr_auc:0.355\n","Epoch: 3 \t Training Loss: 0.146325\n","Epoch: 3 \t Validation pr_auc:0.366\n","Epoch: 4 \t Training Loss: 0.059314\n","Epoch: 4 \t Validation pr_auc:0.377\n","Epoch: 5 \t Training Loss: 0.028156\n","Epoch: 5 \t Validation pr_auc:0.373\n","Epoch: 6 \t Training Loss: 0.016369\n","Epoch: 6 \t Validation pr_auc:0.372\n","Epoch: 7 \t Training Loss: 0.010013\n","Epoch: 7 \t Validation pr_auc:0.377\n","Epoch: 8 \t Training Loss: 0.006848\n","Epoch: 8 \t Validation pr_auc:0.380\n","Epoch: 9 \t Training Loss: 0.004737\n","Epoch: 9 \t Validation pr_auc:0.379\n","Epoch: 10 \t Training Loss: 0.003515\n","Epoch: 10 \t Validation pr_auc:0.378\n"]}],"source":["n_epochs = 10\n","train(retainmodel, train_loader, val_loader, n_epochs)"]},{"cell_type":"code","source":["def test(model, data, test_number):\n","      pr_auc = eval_model(model, test_loader)\n","      print('Test number: {} \\t test pr_auc:{:.3f}'\n","            .format(test_number+1,pr_auc))\n","      \n"],"metadata":{"id":"I_GpBl8ALhVO","executionInfo":{"status":"ok","timestamp":1651957263180,"user_tz":240,"elapsed":20,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test_number = 3\n","for i in range(test_number):\n","  train_test_split = int(len(data)*0.8)\n","  lengths = [train_test_split, len(data) - train_test_split]\n","  train_data, test_data = random_split(data, lengths)\n","\n","\n","  train_val_split = int(len(train_data)*0.5)\n","  lengths = [train_val_split, len(train_data) - train_val_split]\n","  train_data, val_data = random_split(train_data, lengths)\n","\n","  train_loader, val_loader, test_loader = load_data(train_data, val_data, test_data, collate_fn)\n","\n","  newmodel = RETAIN(num_codes = num_codes)\n","  criterion = nn.BCELoss()\n","  optimizer = optim.Adam(newmodel.parameters(), lr=0.001)\n","\n","  n_epochs = 10xw\n","  train(newmodel, train_loader, val_loader, n_epochs,display_results=False)\n","  test(newmodel, test_loader, i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXsXpKwhLmWM","executionInfo":{"status":"ok","timestamp":1651957872996,"user_tz":240,"elapsed":184117,"user":{"displayName":"Jacky S","userId":"12056070040940406337"}},"outputId":"d40ac2b5-d209-4753-f9d8-c49243c6f496"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Test number: 1 \t test pr_auc:0.318\n","Test number: 2 \t test pr_auc:0.325\n","Test number: 3 \t test pr_auc:0.355\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Baseline RETAIN readmission prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}